<!DOCTYPE html>
<html lang="zh-CN" color-mode="light">

  <head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="keywords" content="" />
  <meta name="author" content="Coder109" />
  <meta name="description" content="" />
  
  
  <title>
    
      微调大模型的代码库 
      
      
      |
    
     幻
  </title>

  
    <link rel="apple-touch-icon" href="/images/favicon.ico">
    <link rel="icon" href="/images/favicon.ico">
  

  <!-- Raleway-Font -->
  <link href="https://fonts.googleapis.com/css?family=Raleway&display=swap" rel="stylesheet">

  <!-- hexo site css -->
  <link rel="stylesheet" href="/css/main.css" />
  <link rel="stylesheet" href="//at.alicdn.com/t/font_1886449_67xjft27j1l.css" />
  <!-- 代码块风格 -->
  

  <!-- jquery3.3.1 -->
  
    <script defer type="text/javascript" src="/plugins/jquery.min.js"></script>
  

  <!-- fancybox -->
  
    <link href="/plugins/jquery.fancybox.min.css" rel="stylesheet">
    <script defer type="text/javascript" src="/plugins/jquery.fancybox.min.js"></script>
  
  
<script src="/js/fancybox.js"></script>


  

  

  <script>
    var html = document.documentElement
    const colorMode = localStorage.getItem('color-mode')
    if (colorMode) {
      document.documentElement.setAttribute('color-mode', colorMode)
    }
  </script>
<meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="幻" type="application/atom+xml">
</head>


  <body>
    <div id="app">
      <div class="header">
  <div class="avatar">
    <a href="/">
      <!-- 头像取消懒加载，添加no-lazy -->
      
        <img no-lazy src="/images/favicon.ico" alt="">
      
    </a>
    <div class="nickname"><a href="/">幻</a></div>
  </div>
  <div class="navbar">
    <ul>
      
        <li class="nav-item" data-path="/">
          <a href="/">Home</a>
        </li>
      
        <li class="nav-item" data-path="/archives/">
          <a href="/archives/">Archives</a>
        </li>
      
        <li class="nav-item" data-path="/tags/">
          <a href="/tags/">Tags</a>
        </li>
      
        <li class="nav-item" data-path="/friends/">
          <a href="/friends/">Friends</a>
        </li>
      
        <li class="nav-item" data-path="/about/">
          <a href="/about/">About</a>
        </li>
      
    </ul>
  </div>
</div>


<script src="/js/activeNav.js"></script>



      <div class="flex-container">
        <!-- 文章详情页，展示文章具体内容，url形式：https://yoursite/文章标题/ -->
<!-- 同时为「标签tag」，「朋友friend」，「分类categories」，「关于about」页面的承载页面，具体展示取决于page.type -->


  <!-- LaTex Display -->

  
    <script async type="text/javascript" src="/plugins/mathjax/tex-chtml.js"></script>
  
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      }
    }
  </script>





  <!-- clipboard -->

  
    <script async type="text/javascript" src="/plugins/clipboard.min.js"></script>
  
  
<script src="/js/codeCopy.js"></script>







  

  

  

  
  <!-- 文章内容页 url形式：https://yoursite/文章标题/ -->
  <div class="container post-details" id="post-details">
    <div class="post-content">
      <div class="post-title">微调大模型的代码库</div>
      <div class="post-attach">
        <span class="post-pubtime">
          <i class="iconfont icon-updatetime mr-10" title="更新时间"></i>
          2024-11-04 16:21:54
        </span>
        
              <span class="post-tags">
                <i class="iconfont icon-tags mr-10" title="标签"></i>
                
                <span class="span--tag mr-8">
                  <a href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA/" title="计算机">
                    #计算机
                  </a>
                </span>
                
              </span>
          
      </div>
      <div class="markdown-body">
        <blockquote>
<p>ONLY NOTE</p>
</blockquote>
<h1 id="全量微调"><a href="#全量微调" class="headerlink" title="全量微调"></a>全量微调</h1><p>全量微调是指对大模型的全部参数进行训练。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> LlamaForCausalLM, LlamaTokenizer</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> Trainer, TrainingArguments</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CustomDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, json_file_path, tokenizer, prompt</span>):</span><br><span class="line">        self.json_blocks = json.load(<span class="built_in">open</span>(json_file_path))</span><br><span class="line">        self.tokenizer = tokenizer</span><br><span class="line">        self.prompt = prompt</span><br><span class="line">        self.max_length = <span class="number">100</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.json_blocks)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, idx</span>):</span><br><span class="line">        json_block = self.json_blocks[idx]</span><br><span class="line">        src, tgt = json_block[<span class="string">&quot;src&quot;</span>], json_block[<span class="string">&quot;tgt&quot;</span>]</span><br><span class="line">        src = self.prompt + src</span><br><span class="line">        return_dict =&#123;</span><br><span class="line">            <span class="string">&quot;input_ids&quot;</span>: self.tokenizer(src, return_tensors=<span class="string">&quot;pt&quot;</span>, padding=<span class="string">&quot;max_length&quot;</span>, max_length=self.max_length, truncation=<span class="literal">True</span>).input_ids[<span class="number">0</span>],</span><br><span class="line">            <span class="string">&quot;labels&quot;</span>: self.tokenizer(tgt, return_tensors=<span class="string">&quot;pt&quot;</span>, padding=<span class="string">&quot;max_length&quot;</span>, max_length=self.max_length, truncation=<span class="literal">True</span>).input_ids[<span class="number">0</span>],</span><br><span class="line">        &#125;</span><br><span class="line">        return_dict.update(&#123;<span class="string">&quot;attention_mask&quot;</span>: torch.tensor([<span class="number">1</span>] * self.max_length).to(<span class="string">&quot;cuda&quot;</span>)&#125;)</span><br><span class="line">        <span class="keyword">return</span> return_dict</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">args</span>):</span><br><span class="line">    <span class="comment"># Load Models</span></span><br><span class="line">    tokenizer = LlamaTokenizer.from_pretrained(args.model_name_or_path)</span><br><span class="line">    tokenizer.pad_token = tokenizer.eos_token</span><br><span class="line">    model = LlamaForCausalLM.from_pretrained(</span><br><span class="line">        args.model_name_or_path,</span><br><span class="line">        device_map=<span class="string">&quot;auto&quot;</span>,</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Load Data</span></span><br><span class="line">    dataset = CustomDataset(args.dataset, tokenizer, args.prompt)</span><br><span class="line">    <span class="built_in">print</span>(dataset[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Define Trainer</span></span><br><span class="line">    training_args = TrainingArguments(</span><br><span class="line">        output_dir=args.model_name_or_path,</span><br><span class="line">        learning_rate=<span class="number">2e-5</span>,</span><br><span class="line">        per_device_train_batch_size=<span class="number">2</span>,</span><br><span class="line">        gradient_accumulation_steps=<span class="number">32</span>,</span><br><span class="line">        warmup_steps=<span class="number">100</span>,</span><br><span class="line">        num_train_epochs=<span class="number">5</span>,</span><br><span class="line">        weight_decay=<span class="number">0.01</span>,</span><br><span class="line">        logging_steps=<span class="number">10</span>,</span><br><span class="line">        save_strategy=<span class="string">&quot;epoch&quot;</span>,</span><br><span class="line">        save_total_limit=<span class="number">5</span>,</span><br><span class="line">        evaluation_strategy=<span class="string">&quot;no&quot;</span>,</span><br><span class="line">        fp16=<span class="literal">True</span>,</span><br><span class="line">        tf32=<span class="literal">True</span>,</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    trainer = Trainer(</span><br><span class="line">        model=model,</span><br><span class="line">        tokenizer=tokenizer,</span><br><span class="line">        args=training_args,</span><br><span class="line">        train_dataset=dataset,</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Train Model</span></span><br><span class="line">    trainer.train()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    parser = argparse.ArgumentParser()</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--model_name_or_path&quot;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">&quot;./models/vicuna-7b-v1.5&quot;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--dataset&quot;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">&quot;./data/alpha_train_en_de.json&quot;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--prompt&quot;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">&quot;Please translate following sentence from English to German: &quot;</span>)</span><br><span class="line">    args = parser.parse_args()</span><br><span class="line"></span><br><span class="line">    train(args)</span><br></pre></td></tr></table></figure>

<h1 id="部分微调"><a href="#部分微调" class="headerlink" title="部分微调"></a>部分微调</h1><p>只是对大模型的一部分进行微调，比如说LoRA。直接在上面的代码增加PEFT的部分即可。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> LlamaForCausalLM, LlamaTokenizer</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> Trainer, TrainingArguments</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">from</span> peft <span class="keyword">import</span> LoraConfig, prepare_model_for_int8_training, get_peft_model, get_peft_model_state_dict, set_peft_model_state_dict</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CustomDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, json_file_path, tokenizer, prompt</span>):</span><br><span class="line">        self.json_blocks = json.load(<span class="built_in">open</span>(json_file_path))</span><br><span class="line">        self.tokenizer = tokenizer</span><br><span class="line">        self.prompt = prompt</span><br><span class="line">        self.max_length = <span class="number">100</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.json_blocks)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, idx</span>):</span><br><span class="line">        json_block = self.json_blocks[idx]</span><br><span class="line">        src, tgt = json_block[<span class="string">&quot;src&quot;</span>], json_block[<span class="string">&quot;tgt&quot;</span>]</span><br><span class="line">        src = self.prompt + src</span><br><span class="line">        return_dict =&#123;</span><br><span class="line">            <span class="string">&quot;input_ids&quot;</span>: self.tokenizer(src, return_tensors=<span class="string">&quot;pt&quot;</span>, padding=<span class="string">&quot;max_length&quot;</span>, max_length=self.max_length, truncation=<span class="literal">True</span>).input_ids[<span class="number">0</span>],</span><br><span class="line">            <span class="string">&quot;labels&quot;</span>: self.tokenizer(tgt, return_tensors=<span class="string">&quot;pt&quot;</span>, padding=<span class="string">&quot;max_length&quot;</span>, max_length=self.max_length, truncation=<span class="literal">True</span>).input_ids[<span class="number">0</span>],</span><br><span class="line">        &#125;</span><br><span class="line">        return_dict.update(&#123;<span class="string">&quot;attention_mask&quot;</span>: torch.tensor([<span class="number">1</span>] * self.max_length).to(<span class="string">&quot;cuda&quot;</span>)&#125;)</span><br><span class="line">        <span class="keyword">return</span> return_dict</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">args</span>):</span><br><span class="line">    <span class="comment"># Load Hyperparameters</span></span><br><span class="line">    peft_config = LoraConfig(</span><br><span class="line">        lora_alpha=<span class="number">16</span>,</span><br><span class="line">        lora_dropout=<span class="number">0.1</span>,</span><br><span class="line">        r=<span class="number">64</span>,</span><br><span class="line">        bias=<span class="string">&quot;none&quot;</span>,</span><br><span class="line">        task_type=<span class="string">&quot;CAUSAL_LM&quot;</span>,</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Load Models</span></span><br><span class="line">    tokenizer = LlamaTokenizer.from_pretrained(args.model_name_or_path)</span><br><span class="line">    tokenizer.pad_token = tokenizer.eos_token</span><br><span class="line">    model = LlamaForCausalLM.from_pretrained(</span><br><span class="line">        args.model_name_or_path,</span><br><span class="line">        device_map=<span class="string">&quot;auto&quot;</span>,</span><br><span class="line">    )</span><br><span class="line">    model.add_adapter(<span class="string">&quot;lora&quot;</span>, peft_config)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Load Data</span></span><br><span class="line">    dataset = CustomDataset(args.dataset, tokenizer, args.prompt)</span><br><span class="line">    <span class="built_in">print</span>(dataset[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Define Trainer</span></span><br><span class="line">    training_args = TrainingArguments(</span><br><span class="line">        output_dir=args.model_name_or_path,</span><br><span class="line">        learning_rate=<span class="number">2e-5</span>,</span><br><span class="line">        per_device_train_batch_size=<span class="number">2</span>,</span><br><span class="line">        gradient_accumulation_steps=<span class="number">32</span>,</span><br><span class="line">        warmup_steps=<span class="number">100</span>,</span><br><span class="line">        num_train_epochs=<span class="number">5</span>,</span><br><span class="line">        weight_decay=<span class="number">0.01</span>,</span><br><span class="line">        logging_steps=<span class="number">10</span>,</span><br><span class="line">        save_strategy=<span class="string">&quot;epoch&quot;</span>,</span><br><span class="line">        save_total_limit=<span class="number">5</span>,</span><br><span class="line">        evaluation_strategy=<span class="string">&quot;no&quot;</span>,</span><br><span class="line">        fp16=<span class="literal">True</span>,</span><br><span class="line">        tf32=<span class="literal">True</span>,</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    trainer = Trainer(</span><br><span class="line">        model=model,</span><br><span class="line">        tokenizer=tokenizer,</span><br><span class="line">        args=training_args,</span><br><span class="line">        train_dataset=dataset,</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Train Model</span></span><br><span class="line">    trainer.train()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    parser = argparse.ArgumentParser()</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--model_name_or_path&quot;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">&quot;./models/vicuna-7b-v1.5&quot;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--dataset&quot;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">&quot;./data/alpha_train_en_de.json&quot;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--prompt&quot;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">&quot;Please translate following sentence from English to German: &quot;</span>)</span><br><span class="line">    args = parser.parse_args()</span><br><span class="line"></span><br><span class="line">    train(args)</span><br></pre></td></tr></table></figure>


      </div>
      
        <div class="prev-or-next">
          <div class="post-foot-next">
            
              <a href="/2024/10/29/%E5%A6%82%E4%BD%95%E5%88%9B%E5%BB%BA%E5%B1%9E%E4%BA%8E%E8%87%AA%E5%B7%B1%E7%9A%84MC%E6%9C%8D%E5%8A%A1%E5%99%A8/" target="_self">
                <i class="iconfont icon-chevronleft"></i>
                <span>上一页</span>
              </a>
            
          </div>
          <div class="post-attach">
            <span class="post-pubtime">
              <i class="iconfont icon-updatetime mr-10" title="更新时间"></i>
              2024-11-04 16:21:54
            </span>
            
                  <span class="post-tags">
                    <i class="iconfont icon-tags mr-10" title="标签"></i>
                    
                    <span class="span--tag mr-8">
                      <a href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA/" title="计算机">
                        #计算机
                      </a>
                    </span>
                    
                  </span>
              
          </div>
          <div class="post-foot-prev">
            
              <a href="/2024/11/04/%E7%97%9B%E8%8B%A6%E9%A2%82/" target="_self">
                <span>下一页</span>
                <i class="iconfont icon-chevronright"></i>
              </a>
            
          </div>
        </div>
      
    </div>
    
  <div id="btn-catalog" class="btn-catalog">
    <i class="iconfont icon-catalog"></i>
  </div>
  <div class="post-catalog hidden" id="catalog">
    <div class="title">目录</div>
    <div class="catalog-content">
      
        <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%85%A8%E9%87%8F%E5%BE%AE%E8%B0%83"><span class="toc-text">全量微调</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E9%83%A8%E5%88%86%E5%BE%AE%E8%B0%83"><span class="toc-text">部分微调</span></a></li></ol>
      
    </div>
  </div>

  
<script src="/js/catalog.js"></script>




    
  </div>


        
<div class="footer">
  <div class="social">
    <ul>
      
        <li>
          <a title="rss" href="/atom.xml">
            <i class="iconfont icon-rss"></i>
          </a>
        </li>
      
    </ul>
  </div>
  
    
    <div class="footer-more">
      
        <a target="_blank" rel="noopener" href="https://github.com/zchengsite/hexo-theme-oranges">Copyright © 2024 Oranges</a>
        
    </div>
  
    
    <div class="footer-more">
      
        <a target="_blank" rel="noopener" href="https://github.com/zchengsite/hexo-theme-oranges">Theme by Oranges | Powered by Hexo</a>
        
    </div>
  
  
</div>

      </div>

      <div class="tools-bar">
        <div class="back-to-top tools-bar-item hidden">
  <a href="javascript: void(0)">
    <i class="iconfont icon-chevronup"></i>
  </a>
</div>


<script src="/js/backtotop.js"></script>



        
  <div class="search-icon tools-bar-item" id="search-icon">
    <a href="javascript: void(0)">
      <i class="iconfont icon-search"></i>
    </a>
  </div>

  <div class="search-overlay hidden">
    <div class="search-content" tabindex="0">
      <div class="search-title">
        <span class="search-icon-input">
          <a href="javascript: void(0)">
            <i class="iconfont icon-search"></i>
          </a>
        </span>
        
          <input type="text" class="search-input" id="search-input" placeholder="搜索...">
        
        <span class="search-close-icon" id="search-close-icon">
          <a href="javascript: void(0)">
            <i class="iconfont icon-close"></i>
          </a>
        </span>
      </div>
      <div class="search-result" id="search-result"></div>
    </div>
  </div>

  <script type="text/javascript">
    var inputArea = document.querySelector("#search-input")
    var searchOverlayArea = document.querySelector(".search-overlay")

    inputArea.onclick = function() {
      getSearchFile()
      this.onclick = null
    }

    inputArea.onkeydown = function() {
      if(event.keyCode == 13)
        return false
    }

    function openOrHideSearchContent() {
      let isHidden = searchOverlayArea.classList.contains('hidden')
      if (isHidden) {
        searchOverlayArea.classList.remove('hidden')
        document.body.classList.add('hidden')
        // inputArea.focus()
      } else {
        searchOverlayArea.classList.add('hidden')
        document.body.classList.remove('hidden')
      }
    }

    function blurSearchContent(e) {
      if (e.target === searchOverlayArea) {
        openOrHideSearchContent()
      }
    }

    document.querySelector("#search-icon").addEventListener("click", openOrHideSearchContent, false)
    document.querySelector("#search-close-icon").addEventListener("click", openOrHideSearchContent, false)
    searchOverlayArea.addEventListener("click", blurSearchContent, false)

    var searchFunc = function (path, search_id, content_id) {
      'use strict';
      var $input = document.getElementById(search_id);
      var $resultContent = document.getElementById(content_id);
      $resultContent.innerHTML = "<ul><span class='local-search-empty'>首次搜索，正在载入索引文件，请稍后……<span></ul>";
      $.ajax({
        // 0x01. load xml file
        url: path,
        dataType: "xml",
        success: function (xmlResponse) {
          // 0x02. parse xml file
          var datas = $("entry", xmlResponse).map(function () {
            return {
              title: $("title", this).text(),
              content: $("content", this).text(),
              url: $("url", this).text()
            };
          }).get();
          $resultContent.innerHTML = "";

          $input.addEventListener('input', function () {
            // 0x03. parse query to keywords list
            var str = '<ul class=\"search-result-list\">';
            var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
            $resultContent.innerHTML = "";
            if (this.value.trim().length <= 0) {
              return;
            }
            // 0x04. perform local searching
            datas.forEach(function (data) {
              var isMatch = true;
              var content_index = [];
              if (!data.title || data.title.trim() === '') {
                data.title = "Untitled";
              }
              var orig_data_title = data.title.trim();
              var data_title = orig_data_title.toLowerCase();
              var orig_data_content = data.content.trim().replace(/<[^>]+>/g, "");
              var data_content = orig_data_content.toLowerCase();
              var data_url = data.url;
              var index_title = -1;
              var index_content = -1;
              var first_occur = -1;
              // only match artiles with not empty contents
              if (data_content !== '') {
                keywords.forEach(function (keyword, i) {
                  index_title = data_title.indexOf(keyword);
                  index_content = data_content.indexOf(keyword);

                  if (index_title < 0 && index_content < 0) {
                    isMatch = false;
                  } else {
                    if (index_content < 0) {
                      index_content = 0;
                    }
                    if (i == 0) {
                      first_occur = index_content;
                    }
                    // content_index.push({index_content:index_content, keyword_len:keyword_len});
                  }
                });
              } else {
                isMatch = false;
              }
              // 0x05. show search results
              if (isMatch) {
                str += "<li><a href='" + data_url + "' class='search-result-title'>" + orig_data_title + "</a>";
                var content = orig_data_content;
                if (first_occur >= 0) {
                  // cut out 100 characters
                  var start = first_occur - 20;
                  var end = first_occur + 80;

                  if (start < 0) {
                    start = 0;
                  }

                  if (start == 0) {
                    end = 100;
                  }

                  if (end > content.length) {
                    end = content.length;
                  }

                  var match_content = content.substr(start, end);

                  // highlight all keywords
                  keywords.forEach(function (keyword) {
                    var regS = new RegExp(keyword, "gi");
                    match_content = match_content.replace(regS, "<span class=\"search-keyword\">" + keyword + "</span>");
                  });

                  str += "<p class=\"search-result-abstract\">" + match_content + "...</p>"
                }
                str += "</li>";
              }
            });
            str += "</ul>";
            if (str.indexOf('<li>') === -1) {
              return $resultContent.innerHTML = "<ul><span class='local-search-empty'>没有找到内容，请尝试更换检索词。<span></ul>";
            }
            $resultContent.innerHTML = str;
          });
        },
        error: function(xhr, status, error) {
          $resultContent.innerHTML = ""
          if (xhr.status === 404) {
            $resultContent.innerHTML = "<ul><span class='local-search-empty'>未找到search.xml文件，具体请参考：<a href='https://github.com/zchengsite/hexo-theme-oranges#configuration' target='_black'>configuration</a><span></ul>";
          } else {
            $resultContent.innerHTML = "<ul><span class='local-search-empty'>请求失败，尝试重新刷新页面或稍后重试。<span></ul>";
          }
        }
      });
      $(document).on('click', '#search-close-icon', function() {
        $('#search-input').val('');
        $('#search-result').html('');
      });
    }

    var getSearchFile = function() {
        var path = "/search.xml";
        searchFunc(path, 'search-input', 'search-result');
    }
  </script>




        
  <div class="tools-bar-item theme-icon" id="switch-color-scheme">
    <a href="javascript: void(0)">
      <i id="theme-icon" class="iconfont icon-moon"></i>
    </a>
  </div>

  
<script src="/js/colorscheme.js"></script>





        
  
    <div class="share-icon tools-bar-item">
      <a href="javascript: void(0)" id="share-icon">
        <i class="iconfont iconshare"></i>
      </a>
      <div class="share-content hidden">
        
          <a class="share-item" href="https://twitter.com/intent/tweet?text=' + %E5%BE%AE%E8%B0%83%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BB%A3%E7%A0%81%E5%BA%93 + '&url=' + https%3A%2F%2Fcoder109.github.io%2F2024%2F11%2F04%2F%25E5%25BE%25AE%25E8%25B0%2583%25E5%25A4%25A7%25E6%25A8%25A1%25E5%259E%258B%25E7%259A%2584%25E4%25BB%25A3%25E7%25A0%2581%25E5%25BA%2593%2F + '" target="_blank" title="Twitter">
            <i class="iconfont icon-twitter"></i>
          </a>
        
        
      </div>
    </div>
  
  
<script src="/js/shares.js"></script>



      </div>
    </div>
  
        <style>
            [bg-lazy] {
                background-image: none !important;
                background-color: #eee !important;
            }
        </style>
        <script>
            window.imageLazyLoadSetting = {
                isSPA: false,
                preloadRatio: 1,
                processImages: null,
            };
        </script><script>window.addEventListener("load",function(){var t=/\.(gif|jpg|jpeg|tiff|png)$/i,r=/^data:image\/[a-z]+;base64,/;Array.prototype.slice.call(document.querySelectorAll("img[data-original]")).forEach(function(a){var e=a.parentNode;"A"===e.tagName&&(e.href.match(t)||e.href.match(r))&&(e.href=a.dataset.original)})});</script><script>!function(r){r.imageLazyLoadSetting.processImages=t;var e=r.imageLazyLoadSetting.isSPA,n=r.imageLazyLoadSetting.preloadRatio||1,c=a();function a(){var t=Array.prototype.slice.call(document.querySelectorAll("img[data-original]")),e=Array.prototype.slice.call(document.querySelectorAll("[bg-lazy]"));return t.concat(e)}function t(){e&&(c=a());for(var t,o=0;o<c.length;o++)0<=(t=(t=c[o]).getBoundingClientRect()).bottom&&0<=t.left&&t.top<=(r.innerHeight*n||document.documentElement.clientHeight*n)&&function(){var t,e,n,a,i=c[o];e=function(){c=c.filter(function(t){return i!==t}),r.imageLazyLoadSetting.onImageLoaded&&r.imageLazyLoadSetting.onImageLoaded(i)},(t=i).hasAttribute("bg-lazy")?(t.removeAttribute("bg-lazy"),e&&e()):(n=new Image,a=t.getAttribute("data-original"),n.onload=function(){t.src=a,t.removeAttribute("data-original"),e&&e()},t.src!==a&&(n.src=a))}()}function i(){clearTimeout(t.tId),t.tId=setTimeout(t,500)}t(),document.addEventListener("scroll",i),r.addEventListener("resize",i),r.addEventListener("orientationchange",i)}(this);</script></body>
</html>
